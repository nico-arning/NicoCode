{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96b0eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "CMPD_or_DMSO = \"CMPD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bae604bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"all_plate_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd80db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmso_plates = [col for col in df[\"Metadata_Plate\"].unique() if \"DMSO\" in col]\n",
    "df[\"Metadata_cmpd_or_control\"] = \"CMPD\"\n",
    "df.loc[df[\"Metadata_Plate\"].isin(dmso_plates), \"Metadata_Treatment_concentration\"] = (\n",
    "    \"DMSO_0\"\n",
    ")\n",
    "df.loc[df[\"Metadata_Plate\"].isin(dmso_plates), \"Metadata_Treatment\"] = \"DMSO\"\n",
    "df.loc[df[\"Metadata_Plate\"].isin(dmso_plates), \"Metadata_Concentration\"] = 0.0\n",
    "df.loc[df[\"Metadata_Plate\"].isin(dmso_plates), \"Metadata_cmpd_or_control\"] = \"DMSO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9c0817b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = [col for col in df.columns if col.startswith(\"Metadata_\")]\n",
    "measurement_cols = [col for col in df.columns if not col.startswith(\"Metadata_\")]\n",
    "variances_df = {}\n",
    "for dmso_or_cmpd in df[\"Metadata_cmpd_or_control\"].unique():\n",
    "    subset_df = df[df[\"Metadata_cmpd_or_control\"] == dmso_or_cmpd]\n",
    "    variances_df[dmso_or_cmpd] = subset_df[measurement_cols].var()\n",
    "    \n",
    "variances_df = pd.DataFrame(variances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd4a84d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "melted_variances_df = variances_df.reset_index().melt(id_vars='index', var_name='Measurement', value_name='Variance')\n",
    "plt.figure()\n",
    "sns.boxplot(x='Measurement', y='Variance', data=melted_variances_df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Variance')\n",
    "plt.xlabel('Measurement')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d6fdc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Metadata_cmpd_or_control\"] == CMPD_or_DMSO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38bdc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rank concentrations within each treatment\n",
    "def rank_within_treatment(group):\n",
    "    # Rank the unique concentrations and map them back to the original values\n",
    "    unique_concentrations = group[\"Metadata_Concentration\"].unique()\n",
    "    concentration_rank = {\n",
    "        val: rank for rank, val in enumerate(sorted(unique_concentrations), start=1)\n",
    "    }\n",
    "    group[\"Metadata_Concentration\"] = group[\"Metadata_Concentration\"].map(\n",
    "        concentration_rank\n",
    "    )\n",
    "    return group\n",
    "\n",
    "\n",
    "# Apply the ranking function to each treatment group\n",
    "#df = df.groupby(\"Metadata_Treatment\").apply(rank_within_treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "62417d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "col_dict = {}\n",
    "meta_cols = [col for col in df.columns if col.startswith(\"Metadata_\")]\n",
    "measurement_cols = [col for col in df.columns if not col.startswith(\"Metadata_\")]\n",
    "col_dict[\"Principal Components\"] = []\n",
    "col_dict[\"Most variance per channel\"] = []\n",
    "all_cols = set(meta_cols)\n",
    "channels = [\n",
    "    \"All\",\n",
    "    \"_ER\",\n",
    "    \"_AGP\",\n",
    "    \"_Mito\",\n",
    "    \"_RNA\",\n",
    "    \"_DNA\",\n",
    "    \"Cells\",\n",
    "    \"Cytoplasm\",\n",
    "    \"Image\",\n",
    "    \"Nuclei\",\n",
    "]\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "most_var_cols = df[numerical_cols].var().nlargest(20).index.tolist()\n",
    "col_dict[\"Most variance overall\"] = most_var_cols\n",
    "\n",
    "dmso_data = df[df[\"Metadata_Treatment\"] == \"DMSO\"]\n",
    "treatment_data = df[df[\"Metadata_Treatment\"] != \"DMSO\"]\n",
    "\n",
    "for channel in channels:\n",
    "    if channel == \"All\":\n",
    "        channel_cols = measurement_cols\n",
    "    else:\n",
    "        channel_cols = [col for col in df.columns if channel in col]\n",
    "    channel = channel.replace(\"_\", \"\")\n",
    "    all_cols.update(channel_cols)\n",
    "    most_var_cols = df[channel_cols].var().nlargest(5).index.tolist()\n",
    "    col_dict[\"Most variance per channel\"].extend(most_var_cols)\n",
    "\n",
    "    # Perform PCA\n",
    "    embedding = PCA(n_components=2).fit_transform(df[channel_cols])\n",
    "\n",
    "    # MinMax scale the PCA components\n",
    "    scaler = MinMaxScaler()\n",
    "    embedding = scaler.fit_transform(embedding)\n",
    "\n",
    "    df[f\"{channel}_PC1\"] = embedding[:, 0]\n",
    "    df[f\"{channel}_PC2\"] = embedding[:, 1]\n",
    "\n",
    "    col_dict[\"Principal Components\"].extend([f\"{channel}_PC1\", f\"{channel}_PC2\"])\n",
    "\n",
    "    # Calculate Mahalanobis distance within each Metadata_plate\n",
    "    for plate, group in treatment_data.groupby(\"Metadata_Plate\"):\n",
    "        # Calculate the covariance matrix of the DMSO data for the current plate\n",
    "        plate_dmso_data = dmso_data[dmso_data[\"Metadata_Plate\"] == plate]\n",
    "        if len(plate_dmso_data) > 1:  # Ensure there are enough samples\n",
    "            epsilon = 1e-5  # Small constant for stabilization\n",
    "            cov_matrix = np.cov(plate_dmso_data[channel_cols].T) + np.eye(len(channel_cols)) * epsilon\n",
    "            inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "\n",
    "            # Calculate the mean of the DMSO data for the current plate\n",
    "            mean_dms_data = np.mean(plate_dmso_data[channel_cols], axis=0)\n",
    "\n",
    "            # Calculate Mahalanobis distance for each observation in the group\n",
    "            df.loc[group.index, f'Mahalanobis Distance {channel}'] = group[channel_cols].apply(\n",
    "                lambda x: distance.mahalanobis(x, mean_dms_data, inv_cov_matrix), axis=1\n",
    "            )\n",
    "        else:\n",
    "            # If there's only one observation, set distance to NaN or handle accordingly\n",
    "            df.loc[group.index, f'Mahalanobis Distance {channel}'] = np.nan\n",
    "\n",
    "remaining_cols = [col for col in df.columns if col not in all_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c97c6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mahanolobis_cols = [\n",
    "    col for col in df.columns if \"Mahalanobis\" in col\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d2bef2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Assuming channel_cols is defined as in your code\n",
    "channel_cols = [col for col in df.columns if any(ch in col for ch in channels)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80dc5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cp = [\n",
    "    #'Metadata_Site_Count',\n",
    "    # \"Metadata_Count_Cells\",\n",
    "    # \"Metadata_Count_CellsIncludingEdges\",\n",
    "    # \"Metadata_Count_Cytoplasm\",\n",
    "    # \"Metadata_Count_Nuclei\",\n",
    "    # \"Metadata_Count_NucleiIncludingEdges\",\n",
    "    \"Metadata_Count_Cells\",\n",
    "]\n",
    "df[\"Metadata_Treatment_concentration\"] = (\n",
    "    df[\"Metadata_Treatment\"] + \"_\" + df[\"Metadata_Concentration\"].astype(str)\n",
    ")\n",
    "\n",
    "metadata_exp = [\n",
    "    \"Metadata_Treatment\",\n",
    "    \"Metadata_Concentration\",\n",
    "    # \"Metadata_Treatment_concentration\",\n",
    "]\n",
    "remaining_cols = set(meta_cols) - set(metadata_cp) - set(metadata_exp)\n",
    "remaining_cols = list(remaining_cols)\n",
    "measurement_cols = [col for col in numerical_cols if \"Metadata_\" not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80df3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df[\"Metadata_Treatment_concentration\"] == \"DMSO_0.0\"]\n",
    "# df = df[df[\"Metadata_Plate\"].isin(dmso_plates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "20805eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "metadata_plate_effects_categorical = [\n",
    "    #'Metadata_Plate',\n",
    "    #'Metadata_plate_quantiles_2',\n",
    "    #'Metadata_plate_quantiles_4',\n",
    "    #'Metadata_plate_quantiles_8',\n",
    "]\n",
    "metadata_plate_effects_regression = [\n",
    "    \"Metadata_well_col_distance_to_edge\",\n",
    "    \"Metadata_well_row_distance_to_edge\",\n",
    "    \"Metadata_Ring_position\",\n",
    "]\n",
    "\n",
    "metadata_plate_effects_categorical = [\n",
    "    #\"Metadata_Inside_outside\",\n",
    "    \"Metadata_Plate\",\n",
    "    \"Metadata_Week\",\n",
    "    \"Metadata_Confocal_or_Nonconfocal\",\n",
    "]\n",
    "\n",
    "metadata_plate_effects = (\n",
    "    metadata_plate_effects_categorical + metadata_plate_effects_regression\n",
    ")\n",
    "\n",
    "cols_of_interest = [col for sublist in col_dict.values() for col in sublist]\n",
    "cols_of_interest = list(set(cols_of_interest) - set(metadata_exp))\n",
    "cols_of_interest = list(set(cols_of_interest) - set(metadata_plate_effects))\n",
    "cols_of_interest = [col for col in cols_of_interest if not col.startswith(\"Metadata_\")]\n",
    "cols_of_interest += metadata_cp\n",
    "metadata_pairs = list(product(metadata_plate_effects, cols_of_interest))\n",
    "\n",
    "pcs_and_meta = metadata_cp\n",
    "plate_pcs = list(product(metadata_plate_effects, pcs_and_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b88c47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plot_over_the_PCA = (\n",
    "    metadata_exp\n",
    "    + metadata_cp\n",
    "    + metadata_plate_effects_regression\n",
    "    + metadata_plate_effects_categorical\n",
    ")\n",
    "\n",
    "embedder = PCA(n_components=2).fit_transform(df[metadata_cp + measurement_cols])\n",
    "df[\"All_PC1\"] = embedder[:, 0]\n",
    "df[\"All_PC2\"] = embedder[:, 1]\n",
    "# embedder = PCA(n_components=2).fit_transform(df[metadata_cp])\n",
    "# df[\"Cell_descriptor_PC1\"] = embedder[:, 0]\n",
    "# df[\"Cell_descriptor_PC2\"] = embedder[:, 1]\n",
    "\n",
    "all_pcs = sorted([col for col in df.columns if \"_PC\" in col])\n",
    "pc_pairs = list(zip(all_pcs[::2], all_pcs[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc5d5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import silhouette_score\n",
    "from statsmodels.formula.api import ols\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def quantify_confounding_effects(\n",
    "    df, pc_pairs, confounding_factors, output_dir=\"figures\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Quantify and rank confounding effects on principal components using multiple methods.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        DataFrame containing the PC columns and confounding factors\n",
    "    pc_pairs : list of tuples\n",
    "        List of (PC1, PC2) column name pairs to analyze\n",
    "    confounding_factors : list\n",
    "        List of column names for potential confounding factors\n",
    "    output_dir : str\n",
    "        Directory to save output figures\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing all analysis results\n",
    "    \"\"\"\n",
    "    print(\"Analyzing confounding effects on principal components...\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    import os\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # 1. ANOVA-based approach\n",
    "    print(\"Running ANOVA analysis...\")\n",
    "    effect_sizes = calculate_effect_size(df, pc_pairs, confounding_factors)\n",
    "    results[\"anova\"] = effect_sizes\n",
    "\n",
    "    # 2. Mutual Information approach\n",
    "    print(\"Calculating mutual information...\")\n",
    "    mi_scores = calculate_mutual_info(df, pc_pairs, confounding_factors)\n",
    "    results[\"mutual_info\"] = mi_scores\n",
    "\n",
    "    # 3. Clustering quality approach\n",
    "    print(\"Evaluating clustering quality...\")\n",
    "    clustering_quality = calculate_clustering_quality(df, pc_pairs, confounding_factors)\n",
    "    results[\"clustering\"] = clustering_quality\n",
    "\n",
    "    # 4. Combined ranking\n",
    "    print(\"Creating combined ranking...\")\n",
    "    combined_ranking = create_combined_ranking(\n",
    "        effect_sizes, mi_scores, clustering_quality\n",
    "    )\n",
    "    results[\"combined\"] = combined_ranking\n",
    "\n",
    "    # 5. Visualizations\n",
    "    print(\"Generating visualizations...\")\n",
    "    create_visualizations(\n",
    "        effect_sizes, mi_scores, clustering_quality, combined_ranking, output_dir\n",
    "    )\n",
    "\n",
    "    print(f\"Analysis complete. Visualizations saved to {output_dir}/\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_effect_size(df, pc_pairs, confounding_factors):\n",
    "    \"\"\"Calculate effect size using ANOVA\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for pc1, pc2 in tqdm(pc_pairs, desc=\"ANOVA analysis\"):\n",
    "        for factor in confounding_factors:\n",
    "            # Skip if the factor has too many unique values\n",
    "            if df[factor].nunique() > 100:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # PC1 analysis\n",
    "                model = ols(f\"{pc1} ~ C({factor})\", data=df).fit()\n",
    "                aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "                r_squared_pc1 = model.rsquared\n",
    "                f_value_pc1 = aov_table[\"F\"].iloc[0]\n",
    "                p_value_pc1 = aov_table[\"PR(>F)\"].iloc[0]\n",
    "\n",
    "                # PC2 analysis\n",
    "                model = ols(f\"{pc2} ~ C({factor})\", data=df).fit()\n",
    "                aov_table = sm.stats.anova_lm(model, typ=2)\n",
    "                r_squared_pc2 = model.rsquared\n",
    "                f_value_pc2 = aov_table[\"F\"].iloc[0]\n",
    "                p_value_pc2 = aov_table[\"PR(>F)\"].iloc[0]\n",
    "\n",
    "                # Combined effect (average of PC1 and PC2)\n",
    "                combined_r_squared = (r_squared_pc1 + r_squared_pc2) / 2\n",
    "\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"PC_Pair\": f\"{pc1}-{pc2}\",\n",
    "                        \"Factor\": factor.replace(\"Metadata_\", \"\"),\n",
    "                        \"R_squared_PC1\": r_squared_pc1,\n",
    "                        \"R_squared_PC2\": r_squared_pc2,\n",
    "                        \"Combined_R_squared\": combined_r_squared,\n",
    "                        \"F_value_PC1\": f_value_pc1,\n",
    "                        \"P_value_PC1\": p_value_pc1,\n",
    "                        \"F_value_PC2\": f_value_pc2,\n",
    "                        \"P_value_PC2\": p_value_pc2,\n",
    "                        \"Significant_PC1\": p_value_pc1 < 0.05,\n",
    "                        \"Significant_PC2\": p_value_pc2 < 0.05,\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Could not analyze {factor} for {pc1}-{pc2}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def calculate_mutual_info(df, pc_pairs, confounding_factors):\n",
    "    \"\"\"Calculate mutual information between factors and PCs\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for pc1, pc2 in tqdm(pc_pairs, desc=\"Mutual information\"):\n",
    "        for factor in confounding_factors:\n",
    "            try:\n",
    "                # Convert categorical to numeric if needed\n",
    "                if df[factor].dtype == \"object\" or df[factor].dtype.name == \"category\":\n",
    "                    factor_encoded = pd.factorize(df[factor])[0]\n",
    "                else:\n",
    "                    factor_encoded = df[factor].values\n",
    "\n",
    "                # Calculate mutual information\n",
    "                mi_pc1 = mutual_info_regression(factor_encoded.reshape(-1, 1), df[pc1])[\n",
    "                    0\n",
    "                ]\n",
    "                mi_pc2 = mutual_info_regression(factor_encoded.reshape(-1, 1), df[pc2])[\n",
    "                    0\n",
    "                ]\n",
    "                combined_mi = (mi_pc1 + mi_pc2) / 2\n",
    "\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"PC_Pair\": f\"{pc1}-{pc2}\",\n",
    "                        \"Factor\": factor.replace(\"Metadata_\", \"\"),\n",
    "                        \"MI_PC1\": mi_pc1,\n",
    "                        \"MI_PC2\": mi_pc2,\n",
    "                        \"Combined_MI\": combined_mi,\n",
    "                    }\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {factor}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def calculate_clustering_quality(df, pc_pairs, confounding_factors):\n",
    "    \"\"\"Calculate clustering quality using silhouette score\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for pc1, pc2 in tqdm(pc_pairs, desc=\"Clustering quality\"):\n",
    "        pc_data = df[[pc1, pc2]].values\n",
    "\n",
    "        for factor in confounding_factors:\n",
    "            try:\n",
    "                # Skip if too many unique values or not categorical\n",
    "                if df[factor].nunique() > 100 or df[factor].nunique() < 2:\n",
    "                    continue\n",
    "\n",
    "                labels = df[factor].astype(\"category\").cat.codes.values\n",
    "\n",
    "                # Calculate silhouette score\n",
    "                if len(np.unique(labels)) > 1:  # Need at least 2 clusters\n",
    "                    sil_score = silhouette_score(pc_data, labels, metric=\"euclidean\")\n",
    "\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"PC_Pair\": f\"{pc1}-{pc2}\",\n",
    "                            \"Factor\": factor.replace(\"Metadata_\", \"\"),\n",
    "                            \"Silhouette_Score\": sil_score,\n",
    "                        }\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {factor}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def create_combined_ranking(effect_sizes, mi_scores, clustering_quality):\n",
    "    \"\"\"Combine all metrics into a final ranking\"\"\"\n",
    "    # Normalize each metric to 0-1 scale\n",
    "    for df, metric in [\n",
    "        (effect_sizes, \"Combined_R_squared\"),\n",
    "        (mi_scores, \"Combined_MI\"),\n",
    "        (clustering_quality, \"Silhouette_Score\"),\n",
    "    ]:\n",
    "        if not df.empty:\n",
    "            for pc_pair in df[\"PC_Pair\"].unique():\n",
    "                mask = df[\"PC_Pair\"] == pc_pair\n",
    "                min_val = df.loc[mask, metric].min()\n",
    "                max_val = df.loc[mask, metric].max()\n",
    "                if max_val > min_val:\n",
    "                    df.loc[mask, f\"Normalized_{metric}\"] = (\n",
    "                        df.loc[mask, metric] - min_val\n",
    "                    ) / (max_val - min_val)\n",
    "                else:\n",
    "                    df.loc[mask, f\"Normalized_{metric}\"] = 0\n",
    "\n",
    "    # Combine all metrics\n",
    "    combined = []\n",
    "\n",
    "    for pc_pair in effect_sizes[\"PC_Pair\"].unique():\n",
    "        factors = effect_sizes[effect_sizes[\"PC_Pair\"] == pc_pair][\"Factor\"].unique()\n",
    "\n",
    "        for factor in factors:\n",
    "            combined_score = 0\n",
    "            count = 0\n",
    "\n",
    "            # Add ANOVA score\n",
    "            es_row = effect_sizes[\n",
    "                (effect_sizes[\"PC_Pair\"] == pc_pair)\n",
    "                & (effect_sizes[\"Factor\"] == factor)\n",
    "            ]\n",
    "            if not es_row.empty:\n",
    "                combined_score += es_row[\"Normalized_Combined_R_squared\"].values[0]\n",
    "                count += 1\n",
    "\n",
    "            # Add MI score\n",
    "            mi_row = mi_scores[\n",
    "                (mi_scores[\"PC_Pair\"] == pc_pair) & (mi_scores[\"Factor\"] == factor)\n",
    "            ]\n",
    "            if not mi_row.empty:\n",
    "                combined_score += mi_row[\"Normalized_Combined_MI\"].values[0]\n",
    "                count += 1\n",
    "\n",
    "            # Add clustering score\n",
    "            cl_row = clustering_quality[\n",
    "                (clustering_quality[\"PC_Pair\"] == pc_pair)\n",
    "                & (clustering_quality[\"Factor\"] == factor)\n",
    "            ]\n",
    "            if not cl_row.empty:\n",
    "                combined_score += cl_row[\"Normalized_Silhouette_Score\"].values[0]\n",
    "                count += 1\n",
    "\n",
    "            if count > 0:\n",
    "                combined.append(\n",
    "                    {\n",
    "                        \"PC_Pair\": pc_pair,\n",
    "                        \"Factor\": factor,\n",
    "                        \"Combined_Score\": combined_score / count,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame(combined)\n",
    "\n",
    "\n",
    "def create_visualizations(\n",
    "    effect_sizes, mi_scores, clustering_quality, combined_ranking, output_dir\n",
    "):\n",
    "    \"\"\"Create visualizations for all metrics\"\"\"\n",
    "    # 1. ANOVA heatmap\n",
    "    if not effect_sizes.empty:\n",
    "        pivot_table = effect_sizes.pivot_table(\n",
    "            index=\"Factor\", columns=\"PC_Pair\", values=\"Combined_R_squared\"\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(pivot_table, annot=True, cmap=\"viridis\", fmt=\".2f\")\n",
    "        plt.title(\"Effect Size (R²) of Confounding Factors on PC Pairs\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f\"figures/{CMPD_or_DMSO}/confounding_factors_anova_heatmap.png\",\n",
    "            dpi=100,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        # Bar plot for average effect\n",
    "        avg_effects = (\n",
    "            effect_sizes.groupby(\"Factor\")[\"Combined_R_squared\"]\n",
    "            .mean()\n",
    "            .sort_values(ascending=False)\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=avg_effects.index, y=avg_effects.values)\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title(\"Average Effect Size (R²) of Confounding Factors Across All PC Pairs\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f\"figures/{CMPD_or_DMSO}/confounding_factors_anova_ranking.png\",\n",
    "            dpi=100,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    # 2. Mutual Information heatmap\n",
    "    if not mi_scores.empty:\n",
    "        pivot_table = mi_scores.pivot_table(\n",
    "            index=\"Factor\", columns=\"PC_Pair\", values=\"Combined_MI\"\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(pivot_table, annot=True, cmap=\"viridis\", fmt=\".2f\")\n",
    "        plt.title(\"Mutual Information Between Confounding Factors and PC Pairs\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f\"figures/{CMPD_or_DMSO}/confounding_factors_mi_heatmap.png\",\n",
    "            dpi=100,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    # 3. Clustering quality heatmap\n",
    "    if not clustering_quality.empty:\n",
    "        pivot_table = clustering_quality.pivot_table(\n",
    "            index=\"Factor\", columns=\"PC_Pair\", values=\"Silhouette_Score\"\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(pivot_table, annot=True, cmap=\"viridis\", fmt=\".2f\")\n",
    "        plt.title(\n",
    "            \"Clustering Quality (Silhouette Score) of Confounding Factors on PC Pairs\"\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f\"figures/{CMPD_or_DMSO}/confounding_factors_clustering_heatmap.png\",\n",
    "            dpi=100,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    # 4. Combined ranking heatmap\n",
    "    if not combined_ranking.empty:\n",
    "        pivot_table = combined_ranking.pivot_table(\n",
    "            index=\"Factor\", columns=\"PC_Pair\", values=\"Combined_Score\"\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(pivot_table, annot=True, cmap=\"viridis\", fmt=\".2f\")\n",
    "        plt.title(\"Combined Effect of Confounding Factors on PC Pairs\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f\"figures/{CMPD_or_DMSO}confounding_factors_combined_heatmap.png\",\n",
    "            dpi=100,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        # Bar plot for average combined effect\n",
    "        avg_effects = (\n",
    "            combined_ranking.groupby(\"Factor\")[\"Combined_Score\"]\n",
    "            .mean()\n",
    "            .sort_values(ascending=False)\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=avg_effects.index, y=avg_effects.values)\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.title(\"Average Combined Effect of Confounding Factors Across All PC Pairs\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f\"figures/{CMPD_or_DMSO}confounding_factors_combined_ranking.png\",\n",
    "            dpi=100,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "963a3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = quantify_confounding_effects(df, pc_pairs, plot_over_the_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fb6bd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pc1, pc2 in tqdm(pc_pairs):\n",
    "#     # Create a 4x4 grid of subplots\n",
    "#     fig, axes = plt.subplots(3, 3, figsize=(20, 20))\n",
    "\n",
    "#     # Flatten the axes array for easier indexing\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     # Iterate over the pairs of principal components and the axes\n",
    "#     for i, hue_col in enumerate(plot_over_the_PCA):\n",
    "#         # Create the scatter plot\n",
    "#         sns.scatterplot(\n",
    "#             data=df,\n",
    "#             x=pc1,\n",
    "#             y=pc2,\n",
    "#             hue=hue_col,\n",
    "#             alpha=0.6,  # Increased transparency\n",
    "#             ax=axes[i],\n",
    "#             legend=False,\n",
    "#         )\n",
    "\n",
    "#         # Set the title for each subplot\n",
    "#         title = hue_col.replace(\"Metadata_\", \"\").replace(\"_\", \" \")\n",
    "#         axes[i].set_title(title)\n",
    "\n",
    "#         # Move the legend to a better location\n",
    "#         # axes[i].legend(loc='upper right', bbox_to_anchor=(1.2, 1), title=hue_col)\n",
    "\n",
    "#     # Adjust layout and spacing\n",
    "#     plt.tight_layout(pad=3.0)  # Increase padding between subplots\n",
    "\n",
    "#     # Overall title for the figure (optional)\n",
    "#     # plt.suptitle(\"PCA Scatter Plots by Treatment Concentration\", fontsize=16)\n",
    "\n",
    "#     # Show the figure\n",
    "#     # plt.show()\n",
    "#     if CMPD_or_DMSO == \"DMSO\" or CMPD_or_DMSO == \"CMPD\":\n",
    "#         subfolder = CMPD_or_DMSO\n",
    "#     else:\n",
    "#         subfolder = \"cmpd_dmso_split\"\n",
    "\n",
    "#     plt.savefig(f\"figures/{subfolder}_{pc1}_{pc2}.png\", dpi=100, bbox_inches=\"tight\")\n",
    "\n",
    "#     # Close the plot to free memory\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d1946efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df[\"Metadata_Concentration\"] == df[\"Metadata_Concentration\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8babb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:01<00:00,  6.15s/it]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "if CMPD_or_DMSO == \"CMPD\":\n",
    "    for pc1, pc2 in tqdm(pc_pairs):\n",
    "        for categorical_effects in metadata_plate_effects_categorical:\n",
    "            # print(f\"Plotting {categorical_effects} for {pc1} and {pc2}\")\n",
    "            unique_cats = df[categorical_effects].nunique()\n",
    "            rows = math.ceil(unique_cats / 3)  # Adjust the number of columns as needed\n",
    "            cols = min(unique_cats, 3)  # Set a maximum number of columns\n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(15, 15))\n",
    "            axes = axes.flatten()\n",
    "            for i, cat in enumerate(df[categorical_effects].unique()):\n",
    "                if i == 0:\n",
    "                    legend = True\n",
    "                else:\n",
    "                    legend = False\n",
    "\n",
    "                sns.scatterplot(\n",
    "                    data=df[df[categorical_effects] == cat],\n",
    "                    x=pc1,\n",
    "                    y=pc2,\n",
    "                    hue=\"Metadata_Treatment\",\n",
    "                    style=\"Metadata_Concentration\",\n",
    "                    palette=\"Set1\",\n",
    "                    ax=axes[i],\n",
    "                    legend=legend,\n",
    "                )\n",
    "                axes[i].set_title(f\"{cat}\")\n",
    "\n",
    "            # Place legend outside the subplots\n",
    "            handles, labels = axes[0].get_legend_handles_labels()\n",
    "            fig.legend(\n",
    "                handles,\n",
    "                labels,\n",
    "                loc=\"upper right\",\n",
    "                bbox_to_anchor=(1.1, 1),\n",
    "                bbox_transform=fig.transFigure,\n",
    "            )  # Adjust legend position\n",
    "            axes[0].legend_.remove()  # Remove legend from the first subplot\n",
    "            plt.suptitle(f\"{categorical_effects}\", fontsize=16)\n",
    "            plt.tight_layout(\n",
    "                rect=[0, 0, 0.85, 1]\n",
    "            )  # Adjust layout to make space for the legend\n",
    "\n",
    "            plt.savefig(\n",
    "                f\"figures/{CMPD_or_DMSO}_confounding_factors_{categorical_effects}_{pc1}_{pc2}.png\",\n",
    "                dpi=150,\n",
    "                bbox_inches=\"tight\",\n",
    "            )\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e997a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_pc1 = [\n",
    "    \"All_PC1\",\n",
    "    \"AGP_PC1\",\n",
    "    \"Cytoplasm_PC1\",\n",
    "    \"DNA_PC1\",\n",
    "    \"ER_PC1\",\n",
    "    \"RNA_PC1\",\n",
    "    \"Metadata_Count_Cells\",\n",
    "    \"Metadata_Count_Nuclei\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "085ed50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for effect in [\n",
    "    \"Metadata_Inside_outside\",\n",
    "    \"Metadata_Plate\",\n",
    "    \"Metadata_Week\",\n",
    "    \"Metadata_Confocal_or_Nonconfocal\",\n",
    "    \"Metadata_Treatment\",\n",
    "]:\n",
    "    g = sns.PairGrid(\n",
    "        data=df,\n",
    "        hue=effect,\n",
    "        vars=only_pc1,\n",
    "        corner=True,\n",
    "        # alpha=0.5,\n",
    "        palette=\"Set1\",\n",
    "        # x_vars = only_pc1,\n",
    "        # y_vars = metadata_plate_effects,\n",
    "    )\n",
    "    g.map_lower(sns.scatterplot, alpha=0.5)\n",
    "    g.map_diag(sns.kdeplot)\n",
    "    g.add_legend()\n",
    "    plt.savefig(\n",
    "        f\"figures/{CMPD_or_DMSO}_confounding_factors_scatter_{effect}.png\",\n",
    "        dpi=150,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2cc6ef3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e25df72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing treatment concentrations:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing treatment concentrations: 100%|██████████| 4/4 [00:24<00:00,  6.03s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize results lists\n",
    "statistical_results = []\n",
    "constant_cols = []\n",
    "\n",
    "# Define your confounding variables\n",
    "confounders = [\n",
    "    \"Metadata_Plate\",\n",
    "    \"Metadata_Treatment\",\n",
    "    #\"Metadata_Concentration\",\n",
    "]  # Replace with actual column names\n",
    "\n",
    "# Group the DataFrame by treatment concentration to avoid filtering repeatedly\n",
    "# only_highest_conc = df[df[\"Metadata_Concentration\"] == df[\"Metadata_Concentration\"].max()].copy()\n",
    "grouped_df = df.groupby(\"Metadata_Treatment\")\n",
    "\n",
    "# Outer loop with tqdm\n",
    "for treat_conc, filtered_df in tqdm(\n",
    "    grouped_df, desc=\"Processing treatment concentrations\"\n",
    "):\n",
    "    # Inner loop with tqdm\n",
    "    for x, y in tqdm(\n",
    "        metadata_pairs, desc=f\"Processing metadata pairs for {treat_conc}\", leave=False\n",
    "    ):\n",
    "        try:\n",
    "            # Skip if there's not enough variation in the predictor\n",
    "            if filtered_df[x].nunique() <= 1:\n",
    "                constant_cols.append(\n",
    "                    (treat_conc, x, y, \"Not enough variation in predictor\")\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Skip if there's not enough variation in the outcome\n",
    "            if filtered_df[y].nunique() <= 1:\n",
    "                constant_cols.append(\n",
    "                    (treat_conc, x, y, \"Not enough variation in outcome\")\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Create a list of valid confounders (those present in the DataFrame)\n",
    "            valid_confounders = [\n",
    "                conf\n",
    "                for conf in confounders\n",
    "                if conf in filtered_df.columns and filtered_df[conf].nunique() > 1\n",
    "            ]\n",
    "\n",
    "            # Determine if we're dealing with a categorical predictor\n",
    "            is_categorical = x in metadata_plate_effects_categorical\n",
    "\n",
    "            if is_categorical:\n",
    "                # ANCOVA approach for categorical predictors\n",
    "                formula = f\"{y} ~ C({x})\"\n",
    "                for conf in valid_confounders:\n",
    "                    if pd.api.types.is_numeric_dtype(filtered_df[conf]):\n",
    "                        formula += f\" + {conf}\"\n",
    "                    else:\n",
    "                        formula += f\" + C({conf})\"\n",
    "\n",
    "                model = ols(formula, data=filtered_df).fit()\n",
    "                anova_table = anova_lm(model)\n",
    "\n",
    "                # Extract results for the predictor of interest\n",
    "                if f\"C({x})\" in anova_table.index:\n",
    "                    f_statistic = anova_table.loc[f\"C({x})\", \"F\"]\n",
    "                    p_value = anova_table.loc[f\"C({x})\", \"PR(>F)\"]\n",
    "                    effect_size = np.sqrt(\n",
    "                        f_statistic\n",
    "                        * (len(filtered_df[x].unique()) - 1)\n",
    "                        / (\n",
    "                            f_statistic * (len(filtered_df[x].unique()) - 1)\n",
    "                            + model.df_resid\n",
    "                        )\n",
    "                    )  # Partial eta squared\n",
    "\n",
    "                    statistical_results.append(\n",
    "                        {\n",
    "                            \"treatment_conc\": treat_conc,\n",
    "                            \"predictor\": x,\n",
    "                            \"outcome\": y,\n",
    "                            \"method\": \"ANCOVA\",\n",
    "                            \"f_statistic\": f_statistic,\n",
    "                            \"p_value\": p_value,\n",
    "                            \"effect_size\": effect_size,\n",
    "                            \"r_squared\": model.rsquared,\n",
    "                            \"confounders\": valid_confounders,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    constant_cols.append(\n",
    "                        (treat_conc, x, y, \"Predictor not found in ANOVA table\")\n",
    "                    )\n",
    "\n",
    "            else:\n",
    "                # Multiple regression approach for continuous predictors\n",
    "                # Prepare the predictor variables including confounders\n",
    "                predictors = [x] + valid_confounders\n",
    "\n",
    "                # Convert categorical confounders to dummy variables if needed\n",
    "                formula_parts = [x]\n",
    "                for conf in valid_confounders:\n",
    "                    if pd.api.types.is_numeric_dtype(filtered_df[conf]):\n",
    "                        formula_parts.append(conf)\n",
    "                    else:\n",
    "                        formula_parts.append(f\"C({conf})\")\n",
    "\n",
    "                formula = f\"{y} ~ {' + '.join(formula_parts)}\"\n",
    "                model = ols(formula, data=filtered_df).fit()\n",
    "\n",
    "                # Extract results for the predictor of interest\n",
    "                x_index = (\n",
    "                    model.params.index.get_loc(x) if x in model.params.index else None\n",
    "                )\n",
    "                if x_index is not None:\n",
    "                    x_coef = model.params[x]\n",
    "                    x_pvalue = model.pvalues[x]\n",
    "                    x_stderr = model.bse[x]\n",
    "\n",
    "                    statistical_results.append(\n",
    "                        {\n",
    "                            \"treatment_conc\": treat_conc,\n",
    "                            \"predictor\": x,\n",
    "                            \"outcome\": y,\n",
    "                            \"method\": \"Regression\",\n",
    "                            \"coefficient\": x_coef,\n",
    "                            \"std_error\": x_stderr,\n",
    "                            \"p_value\": x_pvalue,\n",
    "                            \"r_squared\": model.rsquared,\n",
    "                            \"confounders\": valid_confounders,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    constant_cols.append(\n",
    "                        (treat_conc, x, y, \"Predictor not found in regression results\")\n",
    "                    )\n",
    "\n",
    "        except Exception as e:\n",
    "            constant_cols.append((treat_conc, x, y, str(e)))\n",
    "\n",
    "# Convert results to DataFrame for easier analysis\n",
    "results_df = pd.DataFrame(statistical_results)\n",
    "constant_cols_df = pd.DataFrame(\n",
    "    constant_cols, columns=[\"treatment_conc\", \"predictor\", \"outcome\", \"error\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9b1438ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Bonferroni correction\n",
    "results_df[\"adjusted_p_value\"] = results_df[\"p_value\"].fillna(1) * len(results_df)\n",
    "\n",
    "# Ensure adjusted p-values do not exceed 1\n",
    "results_df[\"adjusted_p_value\"] = results_df[\"adjusted_p_value\"].clip(upper=1)\n",
    "\n",
    "results_df.sort_values(by=\"adjusted_p_value\", ascending=True, inplace=True)\n",
    "\n",
    "results_df[\"Rank\"] = results_df[\"adjusted_p_value\"].rank(method=\"first\").astype(int)\n",
    "\n",
    "results_df.to_csv(\"significance_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b0ca1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_plate_effects = results_df.head(20)\n",
    "pc_and_meta_plate_effects = results_df[results_df[\"outcome\"].isin(only_pc1)].head(\n",
    "    20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "87ae71c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meta = df.columns[df.columns.str.startswith(\"Metadata_\")].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "608a3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "max_row = df[\"Metadata_Well_row\"].max() + 1\n",
    "max_col = df[\"Metadata_Well_col\"].max() + 1\n",
    "\n",
    "\n",
    "def plot_plate(row_sig_test, treat_conc, filtered_df):\n",
    "    x = row_sig_test[\"predictor\"]\n",
    "    y = row_sig_test[\"outcome\"]\n",
    "    adjusted_p = row_sig_test[\"adjusted_p_value\"]\n",
    "    rank = row_sig_test[\"Rank\"]\n",
    "\n",
    "    # Prepare position data\n",
    "    if pd.api.types.is_numeric_dtype(filtered_df[x]):\n",
    "        mask_position = filtered_df[x].to_list()\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        mask_position = le.fit_transform(filtered_df[x])\n",
    "\n",
    "    values = filtered_df[y].to_list()\n",
    "\n",
    "    # Initialize masks\n",
    "    position_mask = np.full((max_row, max_col), np.nan)\n",
    "    value_mask = np.full((max_row, max_col), np.nan)\n",
    "    treatment_mask = np.full((max_row, max_col), np.nan)\n",
    "    concentration_mask = np.full((max_row, max_col), np.nan)\n",
    "    stddev_mask = np.full((max_row, max_col), np.nan)\n",
    "    cv_mask = np.full(\n",
    "        (max_row, max_col), np.nan\n",
    "    )  # New mask for coefficient of variation\n",
    "\n",
    "    # Create mappings for categorical data\n",
    "    unique_treatments = filtered_df[\"Metadata_Treatment\"].unique()\n",
    "    treatment_map = {t: i for i, t in enumerate(unique_treatments)}\n",
    "\n",
    "    unique_concentrations = filtered_df[\"Metadata_Concentration\"].unique()\n",
    "    concentration_map = {c: i for i, c in enumerate(unique_concentrations)}\n",
    "\n",
    "    # Populate masks\n",
    "    for i, row in filtered_df.iterrows():\n",
    "        r = int(row[\"Metadata_Well_row\"])\n",
    "        c = int(row[\"Metadata_Well_col\"])\n",
    "        idx = i % len(mask_position)  # Prevent index errors\n",
    "\n",
    "        position_mask[r, c] = mask_position[idx]\n",
    "        value_mask[r, c] = values[idx]\n",
    "        treatment_mask[r, c] = treatment_map[row[\"Metadata_Treatment\"]]\n",
    "        concentration_mask[r, c] = concentration_map[row[\"Metadata_Concentration\"]]\n",
    "\n",
    "    # Calculate median for each well position\n",
    "    grouped_df_median = (\n",
    "        filtered_df.groupby([\"Metadata_Well_row\", \"Metadata_Well_col\"])[y]\n",
    "        .median()\n",
    "        .reset_index()\n",
    "    )\n",
    "    for _, row in grouped_df_median.iterrows():\n",
    "        r = int(row[\"Metadata_Well_row\"])\n",
    "        c = int(row[\"Metadata_Well_col\"])\n",
    "        value_mask[r, c] = row[y]\n",
    "\n",
    "    # Calculate standard deviation for each well position\n",
    "    grouped_df_stddev = (\n",
    "        filtered_df.groupby([\"Metadata_Well_row\", \"Metadata_Well_col\"])[y]\n",
    "        .std()\n",
    "        .reset_index()\n",
    "    )\n",
    "    for _, row in grouped_df_stddev.iterrows():\n",
    "        r = int(row[\"Metadata_Well_row\"])\n",
    "        c = int(row[\"Metadata_Well_col\"])\n",
    "        stddev_mask[r, c] = row[y]\n",
    "\n",
    "    # Calculate coefficient of variation for each well position\n",
    "    grouped_df_cv = (\n",
    "        filtered_df.groupby([\"Metadata_Well_row\", \"Metadata_Well_col\"])[y]\n",
    "        .agg([\"mean\", \"std\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    grouped_df_cv[\"cv\"] = grouped_df_cv[\"std\"] / grouped_df_cv[\"mean\"]\n",
    "    for _, row in grouped_df_cv.iterrows():\n",
    "        r = int(row[\"Metadata_Well_row\"])\n",
    "        c = int(row[\"Metadata_Well_col\"])\n",
    "        cv_mask[r, c] = row[\"cv\"]\n",
    "\n",
    "    # Create figure layout\n",
    "    fig = plt.figure(figsize=(24, 12))  # Adjusted figure size\n",
    "    gs = gridspec.GridSpec(\n",
    "        2, 3, height_ratios=[1, 1], width_ratios=[1, 1, 1]\n",
    "    )  # Two rows, three columns\n",
    "\n",
    "    axes = [\n",
    "        plt.subplot(gs[0, 0]),\n",
    "        plt.subplot(gs[0, 1]),\n",
    "        plt.subplot(gs[0, 2]),\n",
    "        plt.subplot(gs[1, 0]),\n",
    "        plt.subplot(gs[1, 1]),\n",
    "        plt.subplot(gs[1, 2]),\n",
    "    ]  # Adjusted for 2x3 layout\n",
    "\n",
    "    # Plot heatmaps\n",
    "    sns.heatmap(position_mask, cmap=\"Set2\", cbar=True, ax=axes[2])\n",
    "    axes[2].set_title(f\"Positions of {x}\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    sns.heatmap(value_mask, cmap=\"viridis\", cbar=True, ax=axes[1])\n",
    "    axes[1].set_title(f\"Median value of {y}\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    # Treatment heatmap with legend - using updated colormap approach\n",
    "    cmap_treat = plt.colormaps[\"Dark2\"].resampled(len(unique_treatments))\n",
    "    sns.heatmap(treatment_mask, cmap=cmap_treat, cbar=False, ax=axes[0])\n",
    "    axes[0].set_title(\"Treatment\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Add treatment legend\n",
    "    treatment_patches = [\n",
    "        mpatches.Patch(color=cmap_treat(i), label=t)\n",
    "        for i, t in enumerate(unique_treatments)\n",
    "    ]\n",
    "    axes[0].legend(\n",
    "        handles=treatment_patches,\n",
    "        title=\"Treatments\",\n",
    "        bbox_to_anchor=(1.05, 1),\n",
    "        loc=\"upper left\",\n",
    "    )\n",
    "\n",
    "    # Concentration heatmap\n",
    "    cmap_conc = plt.colormaps[\"plasma\"].resampled(len(unique_concentrations))\n",
    "    sns.heatmap(concentration_mask, cmap=cmap_conc, cbar=False, ax=axes[3])\n",
    "    axes[3].set_title(\"Concentration\")\n",
    "    axes[3].axis(\"off\")\n",
    "\n",
    "    # Add concentration legend\n",
    "    concentration_patches = [\n",
    "        mpatches.Patch(color=cmap_conc(i), label=str(c))\n",
    "        for i, c in enumerate(unique_concentrations)\n",
    "    ]\n",
    "    axes[3].legend(\n",
    "        handles=concentration_patches,\n",
    "        title=\"Concentrations\",\n",
    "        bbox_to_anchor=(1.05, 1),\n",
    "        loc=\"upper left\",\n",
    "    )\n",
    "\n",
    "    # Coefficient of Variation heatmap\n",
    "    sns.heatmap(cv_mask, cmap=\"coolwarm\", cbar=True, ax=axes[4])\n",
    "    axes[4].set_title(f\"Coefficient of Variation of {y}\")\n",
    "    axes[4].axis(\"off\")\n",
    "\n",
    "    # Violin plot\n",
    "    sorted_x_values = sorted(filtered_df[x].unique())\n",
    "    sns.violinplot(data=filtered_df, x=x, y=y, cut=0, ax=axes[5], order=sorted_x_values)\n",
    "    # Format labels\n",
    "    x_label = x.replace(\"_\", \" \").replace(\"Metadata_\", \"\")\n",
    "    y_label = y.replace(\"_\", \" \").replace(\"Metadata_\", \"\")\n",
    "\n",
    "    axes[5].set_title(f\"Adjusted p-value: {adjusted_p:.2e}\")\n",
    "    axes[5].set_xlabel(x_label)\n",
    "    axes[5].set_ylabel(y_label)\n",
    "\n",
    "    # Set x-tick labels\n",
    "    unique_labels = filtered_df[x].unique()\n",
    "    axes[5].set_xticks(\n",
    "        range(len(unique_labels))\n",
    "    )  # Set the ticks to correspond to the number of unique labels\n",
    "    axes[5].set_xticklabels(\n",
    "        unique_labels, rotation=45, ha=\"right\"\n",
    "    )  # Set the tick labels\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if treat_conc == \"DMSO\" or treat_conc == \"CMPD\":\n",
    "        subfolder = treat_conc\n",
    "    else:\n",
    "        subfolder = \"cmpd_dmso_split\"\n",
    "    plt.savefig(\n",
    "        f\"figures/{subfolder}/Rank_{rank}__{adjusted_p:.2e}_{treat_conc}_{x}_{y}_.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1d89167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Precompute the unique treatment concentrations and their corresponding filtered DataFrames\n",
    "# grouped_data_DMSO_control = {\n",
    "#     treat_conc: filtered_df\n",
    "#     for treat_conc, filtered_df in df.groupby(\"Metadata_cmpd_or_control\")\n",
    "# }\n",
    "# grouped_data_treat_conc = {\n",
    "#     treat_conc: filtered_df\n",
    "#     for treat_conc, filtered_df in df.groupby(\"Metadata_Treatment_concentration\")\n",
    "# }\n",
    "# grouped_data_treat_conc2 = {\n",
    "#     treat_conc: filtered_df\n",
    "#     for treat_conc, filtered_df in df.groupby(\"Metadata_Treatment_concentration\")\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1b1375f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "max_row = df[\"Metadata_Well_row\"].max() + 1\n",
    "max_col = df[\"Metadata_Well_col\"].max() + 1\n",
    "\n",
    "def plot_heatmap_with_std(row_sig_test, filtered_df):\n",
    "    x = row_sig_test[\"predictor\"]\n",
    "    y = row_sig_test[\"outcome\"]\n",
    "    adjusted_p = row_sig_test[\"adjusted_p_value\"]\n",
    "\n",
    "    # Prepare position data\n",
    "    if pd.api.types.is_numeric_dtype(filtered_df[x]):\n",
    "        le = LabelEncoder()\n",
    "        mask_position = filtered_df[x].to_list()\n",
    "    else:\n",
    "        le = LabelEncoder()\n",
    "        mask_position = le.fit_transform(filtered_df[x])\n",
    "\n",
    "    values = filtered_df[y].to_list()\n",
    "\n",
    "    # Initialize masks\n",
    "    position_mask = np.full((max_row, max_col), np.nan)\n",
    "    value_mask = np.full((max_row, max_col), np.nan)\n",
    "    stddev_mask = np.full((max_row, max_col), np.nan)\n",
    "\n",
    "    # Populate masks\n",
    "    for i, row in filtered_df.iterrows():\n",
    "        r = int(row[\"Metadata_Well_row\"])\n",
    "        c = int(row[\"Metadata_Well_col\"])\n",
    "        idx = i % len(mask_position)  # Prevent index errors\n",
    "\n",
    "        position_mask[r, c] = mask_position[idx]\n",
    "        value_mask[r, c] = values[idx]\n",
    "\n",
    "    # Calculate standard deviation for each well position\n",
    "    grouped_df_stddev = (\n",
    "        filtered_df.groupby([\"Metadata_Well_row\", \"Metadata_Well_col\"])[y]\n",
    "        .std()\n",
    "        .reset_index()\n",
    "    )\n",
    "    for _, row in grouped_df_stddev.iterrows():\n",
    "        r = int(row[\"Metadata_Well_row\"])\n",
    "        c = int(row[\"Metadata_Well_col\"])\n",
    "        stddev_mask[r, c] = row[y]\n",
    "\n",
    "    # Create figure layout\n",
    "    fig = plt.figure(figsize=(14, 6))  # Adjusted figure size\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1])  # One row, two columns\n",
    "\n",
    "    axes = [\n",
    "        plt.subplot(gs[0, 0]),\n",
    "        plt.subplot(gs[0, 1]),\n",
    "    ]  # Adjusted for 1x2 layout\n",
    "\n",
    "    # Plot heatmaps\n",
    "    sns.heatmap(value_mask, cmap=\"viridis\", cbar=True, ax=axes[0])\n",
    "    axes[0].set_title(f\"Values of {y}\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    sns.heatmap(stddev_mask, cmap=\"coolwarm\", cbar=True, ax=axes[1])\n",
    "    axes[1].set_title(f\"Standard Deviation of {y}\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f\"figures/plate_plot_{y}.png\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f98c7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the top plate effects and generate violin plots\n",
    "# for i, row in tqdm(\n",
    "#     pc_and_meta_plate_effects.iterrows(),\n",
    "#     desc=\"Processing metadata pairs\",\n",
    "#     total=len(pc_and_meta_plate_effects),\n",
    "# ):\n",
    "#     #if row[\"Rank\"] > 100:\n",
    "#     #    continue\n",
    "#     for i, (treat_conc, filtered_df) in enumerate(grouped_data_DMSO_control.items()):\n",
    "#         plot_plate(row, treat_conc, filtered_df)\n",
    "#         if i == 0:\n",
    "#             plot_heatmap_with_std(row, filtered_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "45b2d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the top plate effects and generate violin plots\n",
    "# if CMPD_or_DMSO == \"CMPD\":\n",
    "#     for i, row in tqdm(\n",
    "#         pc_and_meta_plate_effects.iterrows(),\n",
    "#         desc=\"Processing metadata pairs\",\n",
    "#         total=len(pc_and_meta_plate_effects),\n",
    "#     ):\n",
    "#         if row[\"Rank\"] > 100:\n",
    "#             continue\n",
    "#         for treat_conc, filtered_df in grouped_data_treat_conc.items():\n",
    "#             plot_plate(row, treat_conc, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "acb80042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the top plate effects and generate violin plots\n",
    "# for i, row in tqdm(pc_and_meta_plate_effects.iterrows(), desc=\"Processing metadata pairs\", total = len(pc_and_meta_plate_effects)):\n",
    "#     for treat_conc, filtered_df in grouped_data_treat_conc.items():\n",
    "#         plot_plate(row, treat_conc, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b2432f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Iterate over the top plate effects and generate violin plots\n",
    "# for i, row in tqdm(\n",
    "#     top_plate_effects.iterrows(),\n",
    "#     desc=\"Processing metadata pairs\",\n",
    "#     total=len(top_plate_effects),\n",
    "# ):\n",
    "#     if row[\"Rank\"] > 100:\n",
    "#         continue\n",
    "#     for treat_conc, filtered_df in grouped_data_treat_conc2.items():\n",
    "#         plot_plate(row, treat_conc, filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b3285134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "# Generate the violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "07eea3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to process each treatment concentration with its metadata pairs\n",
    "# def process_treatment(treat_conc):\n",
    "#     for pair in metadata_pairs:\n",
    "#         violinplot(pair, treat_conc, df)\n",
    "\n",
    "\n",
    "# # Use the unique treatment concentrations and apply the processing function\n",
    "# df[\"Metadata_Treatment_concentration\"].unique().map(process_treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "79c0ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_cols = [col for col in df.columns if col.startswith(\"Metadata_\")]\n",
    "measurement_cols = [col for col in df.columns if not col.startswith(\"Metadata_\")]\n",
    "\n",
    "# Select the 1000 measurement columns with the highest variance\n",
    "top_measurement_cols = df[measurement_cols].var().nlargest(1000).index.tolist()\n",
    "measurement_cols = top_measurement_cols\n",
    "#df = df[metadata_cols + measurement_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "37823cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.multitest as multi\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.formula.api import ols\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def filter_columns_by_variance(df, threshold=0.01):\n",
    "    \"\"\"Filter out columns with variance below the threshold.\"\"\"\n",
    "    measurement_cols = [col for col in df.columns if not col.startswith(\"Metadata_\")]\n",
    "    variances = df[measurement_cols].var()\n",
    "    filtered_cols = variances[variances > threshold].index.tolist()\n",
    "    return df[\n",
    "        filtered_cols + [col for col in df.columns if col.startswith(\"Metadata_\")]\n",
    "    ]\n",
    "\n",
    "\n",
    "def analyze_position_effects(df_control):\n",
    "    \"\"\"Analyze position effects using only the DMSO control data\"\"\"\n",
    "\n",
    "    metadata_cols = [col for col in df_control.columns if col.startswith(\"Metadata_\")]\n",
    "    measurement_cols = [\n",
    "        col for col in df_control.columns if not col.startswith(\"Metadata_\")\n",
    "    ]\n",
    "\n",
    "    position_effects = []\n",
    "\n",
    "    for measure in tqdm(measurement_cols, desc=\"Analyzing position effects\"):\n",
    "        temp_df = df_control.copy()\n",
    "        temp_df[\"y\"] = temp_df[measure]\n",
    "        model_row = ols(\"y ~ C(Metadata_well_row_distance_to_edge)\", data=temp_df).fit()\n",
    "        anova_row = sm.stats.anova_lm(model_row, typ=2)\n",
    "        p_value_row = anova_row.loc[\"C(Metadata_well_row_distance_to_edge)\", \"PR(>F)\"]\n",
    "\n",
    "        model_col = ols(\"y ~ C(Metadata_well_col_distance_to_edge)\", data=temp_df).fit()\n",
    "        anova_col = sm.stats.anova_lm(model_col, typ=2)\n",
    "        p_value_col = anova_col.loc[\"C(Metadata_well_col_distance_to_edge)\", \"PR(>F)\"]\n",
    "\n",
    "        ss_total_row = model_row.ssr + model_row.ess\n",
    "        eta_squared_row = model_row.ssr / ss_total_row\n",
    "\n",
    "        ss_total_col = model_col.ssr + model_col.ess\n",
    "        eta_squared_col = model_col.ssr / ss_total_col\n",
    "\n",
    "        position_effects.append(\n",
    "            {\n",
    "                \"measurement\": measure,\n",
    "                \"p_value_row\": p_value_row,\n",
    "                \"p_value_col\": p_value_col,\n",
    "                \"eta_squared_row\": eta_squared_row,\n",
    "                \"eta_squared_col\": eta_squared_col,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    position_df = pd.DataFrame(position_effects)\n",
    "    position_df[\"p_adj_row\"] = multi.fdrcorrection(position_df[\"p_value_row\"])[1]\n",
    "    position_df[\"p_adj_col\"] = multi.fdrcorrection(position_df[\"p_value_col\"])[1]\n",
    "\n",
    "    position_df[\"combined_effect\"] = (\n",
    "        position_df[\"eta_squared_row\"] + position_df[\"eta_squared_col\"]\n",
    "    )\n",
    "    position_df = position_df.sort_values(\"combined_effect\", ascending=False)\n",
    "\n",
    "    # Save intermediate results\n",
    "    position_df.to_csv(\"position_effects.csv\", index=False)\n",
    "\n",
    "    return position_df\n",
    "\n",
    "\n",
    "def analyze_plate_batch_effects(df_control):\n",
    "    \"\"\"Analyze batch effects between plates within the same week\"\"\"\n",
    "\n",
    "    metadata_cols = [col for col in df_control.columns if col.startswith(\"Metadata_\")]\n",
    "    measurement_cols = [\n",
    "        col for col in df_control.columns if not col.startswith(\"Metadata_\")\n",
    "    ]\n",
    "\n",
    "    plate_effects = []\n",
    "\n",
    "    for week in tqdm(\n",
    "        df_control[\"Metadata_Week\"].unique(), desc=\"Analyzing plate batch effects\"\n",
    "    ):\n",
    "        week_data = df_control[df_control[\"Metadata_Week\"] == week]\n",
    "\n",
    "        for measure in measurement_cols:\n",
    "            temp_df = week_data.copy()\n",
    "            temp_df[\"y\"] = temp_df[measure]\n",
    "\n",
    "            model = ols(\"y ~ C(Metadata_Plate)\", data=temp_df).fit()\n",
    "            anova = sm.stats.anova_lm(model, typ=2)\n",
    "            p_value = anova.loc[\"C(Metadata_Plate)\", \"PR(>F)\"]\n",
    "\n",
    "            ss_total = model.ssr + model.ess\n",
    "            eta_squared = model.ssr / ss_total\n",
    "\n",
    "            plate_effects.append(\n",
    "                {\n",
    "                    \"measurement\": measure,\n",
    "                    \"week\": week,\n",
    "                    \"p_value\": p_value,\n",
    "                    \"eta_squared\": eta_squared,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    plate_df = pd.DataFrame(plate_effects)\n",
    "    plate_df[\"p_adj\"] = multi.fdrcorrection(plate_df[\"p_value\"])[1]\n",
    "\n",
    "    avg_effects = plate_df.groupby(\"measurement\")[\"eta_squared\"].mean().reset_index()\n",
    "    avg_effects = avg_effects.sort_values(\"eta_squared\", ascending=False)\n",
    "\n",
    "    # Save intermediate results\n",
    "    plate_df.to_csv(\"plate_effects.csv\", index=False)\n",
    "\n",
    "    return plate_df, avg_effects\n",
    "\n",
    "\n",
    "def analyze_week_batch_effects(df_control):\n",
    "    \"\"\"Analyze batch effects between different weeks\"\"\"\n",
    "\n",
    "    metadata_cols = [col for col in df_control.columns if col.startswith(\"Metadata_\")]\n",
    "    measurement_cols = [\n",
    "        col for col in df_control.columns if not col.startswith(\"Metadata_\")\n",
    "    ]\n",
    "\n",
    "    week_effects = []\n",
    "\n",
    "    for measure in tqdm(measurement_cols, desc=\"Analyzing week batch effects\"):\n",
    "        temp_df = df_control.copy()\n",
    "        temp_df[\"y\"] = temp_df[measure]\n",
    "\n",
    "        model = ols(\"y ~ C(Metadata_Week)\", data=temp_df).fit()\n",
    "        anova = sm.stats.anova_lm(model, typ=2)\n",
    "        p_value = anova.loc[\"C(Metadata_Week)\", \"PR(>F)\"]\n",
    "\n",
    "        ss_total = model.ssr + model.ess\n",
    "        eta_squared = model.ssr / ss_total\n",
    "\n",
    "        week_effects.append(\n",
    "            {\"measurement\": measure, \"p_value\": p_value, \"eta_squared\": eta_squared}\n",
    "        )\n",
    "\n",
    "    week_df = pd.DataFrame(week_effects)\n",
    "    week_df[\"p_adj\"] = multi.fdrcorrection(week_df[\"p_value\"])[1]\n",
    "\n",
    "    week_df = week_df.sort_values(\"eta_squared\", ascending=False)\n",
    "\n",
    "    # Save intermediate results\n",
    "    week_df.to_csv(\"week_effects.csv\", index=False)\n",
    "\n",
    "    return week_df\n",
    "\n",
    "\n",
    "def visualize_batch_effects(df):\n",
    "    \"\"\"Use PCA to visualize batch effects\"\"\"\n",
    "\n",
    "    metadata_cols = [col for col in df.columns if col.startswith(\"Metadata_\")]\n",
    "    measurement_cols = [col for col in df.columns if not col.startswith(\"Metadata_\")]\n",
    "\n",
    "    X = df[measurement_cols].copy()\n",
    "    X = (X - X.mean()) / X.std()\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(X)\n",
    "\n",
    "    pca_df = pd.DataFrame(\n",
    "        {\n",
    "            \"PC1\": pca_result[:, 0],\n",
    "            \"PC2\": pca_result[:, 1],\n",
    "            \"Week\": df[\"Metadata_Week\"],\n",
    "            \"Plate\": df[\"Metadata_Plate\"],\n",
    "            \"Row\": df[\"Metadata_well_row_distance_to_edge\"],\n",
    "            \"Column\": df[\"Metadata_well_col_distance_to_edge\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", hue=\"Week\", data=pca_df, ax=axes[0])\n",
    "    axes[0].set_title(\"PCA by Week\")\n",
    "\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", hue=\"Plate\", data=pca_df, ax=axes[1])\n",
    "    axes[1].set_title(\"PCA by Plate\")\n",
    "\n",
    "    subset = pca_df.sample(min(1000, len(pca_df)))\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", hue=\"Row\", data=subset, ax=axes[2])\n",
    "    axes[2].set_title(\"PCA by Row Position (Sample)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"figures/visualise_batch_effects.png\",\n",
    "        dpi=150,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return pca, pca_df\n",
    "\n",
    "\n",
    "def rank_measurements_by_batch_sensitivity(position_df, plate_avg_effects, week_df):\n",
    "    \"\"\"Combine all analyses to rank measurements by their sensitivity to batch effects\"\"\"\n",
    "\n",
    "    position_max = position_df[\"combined_effect\"].max()\n",
    "    position_df[\"norm_position_effect\"] = (\n",
    "        position_df[\"combined_effect\"] / position_max if position_max > 0 else 0\n",
    "    )\n",
    "\n",
    "    plate_max = plate_avg_effects[\"eta_squared\"].max()\n",
    "    plate_avg_effects[\"norm_plate_effect\"] = (\n",
    "        plate_avg_effects[\"eta_squared\"] / plate_max if plate_max > 0 else 0\n",
    "    )\n",
    "\n",
    "    week_max = week_df[\"eta_squared\"].max()\n",
    "    week_df[\"norm_week_effect\"] = (\n",
    "        week_df[\"eta_squared\"] / week_max if week_max > 0 else 0\n",
    "    )\n",
    "\n",
    "    merged = (\n",
    "        position_df[[\"measurement\", \"norm_position_effect\"]]\n",
    "        .merge(\n",
    "            plate_avg_effects[[\"measurement\", \"norm_plate_effect\"]], on=\"measurement\"\n",
    "        )\n",
    "        .merge(week_df[[\"measurement\", \"norm_week_effect\"]], on=\"measurement\")\n",
    "    )\n",
    "\n",
    "    merged[\"composite_score\"] = (\n",
    "        merged[\"norm_position_effect\"]\n",
    "        + merged[\"norm_plate_effect\"]\n",
    "        + merged[\"norm_week_effect\"]\n",
    "    ) / 3\n",
    "\n",
    "    merged = merged.sort_values(\"composite_score\", ascending=False)\n",
    "\n",
    "    # Save intermediate results\n",
    "    merged.to_csv(\"ranked_measurements.csv\", index=False)\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def visualize_top_affected_measurements(ranked_df, df, top_n=10):\n",
    "    \"\"\"Visualize the top affected measurements across different batch factors\"\"\"\n",
    "\n",
    "    # Get top measurements\n",
    "    top_measurements = ranked_df.head(top_n)[\"measurement\"].tolist()\n",
    "\n",
    "    # Create a multi-panel figure\n",
    "    fig, axes = plt.subplots(len(top_measurements), 3, figsize=(18, 4 * top_n))\n",
    "\n",
    "    for i, measure in enumerate(top_measurements):\n",
    "        # Plot by week\n",
    "        sns.boxplot(x=\"Metadata_Week\", y=measure, data=df, ax=axes[i, 0])\n",
    "        axes[i, 0].set_title(f\"{measure} by Week\")\n",
    "        axes[i, 0].tick_params(axis=\"x\", rotation=45)  # Rotate x-tick labels\n",
    "\n",
    "        # Plot by plate\n",
    "        sns.boxplot(x=\"Metadata_Plate\", y=measure, data=df, ax=axes[i, 1])\n",
    "        axes[i, 1].set_title(f\"{measure} by Plate\")\n",
    "        axes[i, 1].tick_params(axis=\"x\", rotation=45)  # Rotate x-tick labels\n",
    "\n",
    "        # Plot by row\n",
    "        sns.boxplot(\n",
    "            x=\"Metadata_well_row_distance_to_edge\", y=measure, data=df, ax=axes[i, 2]\n",
    "        )\n",
    "        axes[i, 2].set_title(f\"{measure} by Row\")\n",
    "        axes[i, 2].tick_params(axis=\"x\", rotation=45)  # Rotate x-tick labels\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "    plt.savefig(\"figures/top_affected_measurements.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def build_correction_models(df_control, top_affected_measurements):\n",
    "    \"\"\"Build correction models for the most affected measurements\"\"\"\n",
    "\n",
    "    correction_models = {}\n",
    "\n",
    "    def fit_model(measure):\n",
    "        # Build a model that accounts for position, plate, and week effects\n",
    "        formula = f\"{measure} ~ C(Metadata_well_row_distance_to_edge) + C(Metadata_well_col_distance_to_edge) + C(Metadata_Week) + C(Metadata_Plate)\"\n",
    "        model = ols(formula, data=df_control).fit()\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"formula\": formula,\n",
    "            \"r_squared\": model.rsquared,\n",
    "            \"coefficients\": model.params.to_dict(),\n",
    "        }\n",
    "\n",
    "    # Parallel processing of models\n",
    "    correction_models = {\n",
    "        measure: fit_model(measure) for measure in top_affected_measurements\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        measure: model\n",
    "        for measure, model in zip(top_affected_measurements, correction_models)\n",
    "    }\n",
    "\n",
    "\n",
    "def visualize_spatial_effects(df_control, measurement, week=1, plate=1):\n",
    "    \"\"\"Create a heatmap visualization of a measurement across the plate\"\"\"\n",
    "\n",
    "    # Filter data for specific week and plate\n",
    "    plate_data = df_control[\n",
    "        (df_control[\"Metadata_Week\"] == week) & (df_control[\"Metadata_Plate\"] == plate)\n",
    "    ].copy()\n",
    "\n",
    "    # Check if plate_data is empty\n",
    "    if plate_data.empty:\n",
    "        print(\n",
    "            f\"No data available for Week {week} and Plate {plate}. Skipping heatmap visualization.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Create a pivot table with rows and columns of the plate\n",
    "    plate_pivot = plate_data.pivot_table(\n",
    "        index=\"Metadata_well_row_distance_to_edge\",\n",
    "        columns=\"Metadata_well_col_distance_to_edge\",\n",
    "        values=measurement,\n",
    "        aggfunc=\"mean\",\n",
    "    )\n",
    "\n",
    "    # Check if the pivot table is empty\n",
    "    if plate_pivot.empty:\n",
    "        print(\n",
    "            f\"No data available for measurement '{measurement}' in Week {week} and Plate {plate}. Skipping heatmap visualization.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(plate_pivot, cmap=\"viridis\", annot=False)\n",
    "    plt.title(f\"Spatial Distribution of {measurement} (Week {week}, Plate {plate})\")\n",
    "    plt.savefig(\n",
    "        f\"figures/heatmap_{measurement}_Week{week}_Plate{plate}.png\",\n",
    "        dpi=150,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def feature_selection_for_large_datasets(df_control, max_features=1000):\n",
    "    \"\"\"Select most variable features for analysis when dealing with very large datasets\"\"\"\n",
    "\n",
    "    metadata_cols = [col for col in df_control.columns if col.startswith(\"Metadata_\")]\n",
    "    measurement_cols = [\n",
    "        col for col in df_control.columns if not col.startswith(\"Metadata_\")\n",
    "    ]\n",
    "\n",
    "    cv_values = {}\n",
    "    for col in measurement_cols:\n",
    "        mean = df_control[col].mean()\n",
    "        std = df_control[col].std()\n",
    "        cv = std / mean if mean != 0 else 0\n",
    "        cv_values[col] = abs(cv)  # Use absolute value\n",
    "\n",
    "    sorted_features = sorted(cv_values.items(), key=lambda x: x[1], reverse=True)\n",
    "    selected_features = [feat[0] for feat in sorted_features[:max_features]]\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "def main_analysis(df, checkpoint_dir=\"checkpoints\"):\n",
    "    \"\"\"Run the complete analysis pipeline\"\"\"\n",
    "\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Filter for control (DMSO) data\n",
    "    df_control = df[df[\"Metadata_Treatment\"] == \"DMSO\"].copy()\n",
    "\n",
    "    # Filter columns by variance\n",
    "    df_control = filter_columns_by_variance(df_control, threshold=0.01)\n",
    "\n",
    "    checkpoint_files = {\n",
    "        \"position_effects\": os.path.join(checkpoint_dir, \"position_effects.csv\"),\n",
    "        \"plate_effects\": os.path.join(checkpoint_dir, \"plate_effects.csv\"),\n",
    "        \"week_effects\": os.path.join(checkpoint_dir, \"week_effects.csv\"),\n",
    "        \"ranked_measurements\": os.path.join(checkpoint_dir, \"ranked_measurements.csv\"),\n",
    "    }\n",
    "\n",
    "    # Checkpoint for position effects\n",
    "    if os.path.exists(checkpoint_files[\"position_effects\"]):\n",
    "        position_effects = pd.read_csv(checkpoint_files[\"position_effects\"])\n",
    "    else:\n",
    "        print(\"1. Analyzing position effects...\")\n",
    "        position_effects = analyze_position_effects(df_control)\n",
    "\n",
    "    # Checkpoint for plate effects\n",
    "    if os.path.exists(checkpoint_files[\"plate_effects\"]):\n",
    "        plate_effects, plate_avg_effects = (\n",
    "            pd.read_csv(checkpoint_files[\"plate_effects\"]),\n",
    "            pd.read_csv(checkpoint_files[\"plate_avg_effects\"]),\n",
    "        )\n",
    "    else:\n",
    "        print(\"2. Analyzing plate-to-plate batch effects...\")\n",
    "        plate_effects, plate_avg_effects = analyze_plate_batch_effects(df_control)\n",
    "\n",
    "    # Checkpoint for week effects#\n",
    "    if os.path.exists(checkpoint_files[\"week_effects\"]):\n",
    "        week_effects = pd.read_csv(checkpoint_files[\"week_effects\"])\n",
    "    else:\n",
    "        print(\"3. Analyzing week-to-week batch effects...\")\n",
    "        week_effects = analyze_week_batch_effects(df_control)\n",
    "\n",
    "    print(\"4. Visualizing batch effects using PCA...\")\n",
    "    pca, pca_df = visualize_batch_effects(df_control)\n",
    "\n",
    "    print(\"5. Ranking measurements by batch effect sensitivity...\")\n",
    "    ranked_measurements = rank_measurements_by_batch_sensitivity(\n",
    "        position_effects, plate_avg_effects, week_effects\n",
    "    )\n",
    "\n",
    "    print(\"6. Visualizing top affected measurements...\")\n",
    "    visualize_top_affected_measurements(ranked_measurements, df_control, top_n=10)\n",
    "\n",
    "    top_measurement = ranked_measurements.iloc[0][\"measurement\"]\n",
    "    print(f\"7. Visualizing spatial effects for {top_measurement}...\")\n",
    "    visualize_spatial_effects(df_control, top_measurement)\n",
    "\n",
    "    print(\"8. Building correction models...\")\n",
    "    top_measurements = ranked_measurements.head(20)[\"measurement\"].tolist()\n",
    "    correction_models = build_correction_models(df_control, top_measurements)\n",
    "\n",
    "    print(\"\\nSummary of Batch Effects Analysis:\")\n",
    "    print(f\"Total measurements analyzed: {len(position_effects)}\")\n",
    "    print(\"Top 10 measurements most affected by batch effects:\")\n",
    "    print(\n",
    "        ranked_measurements.head(10)[\n",
    "            [\n",
    "                \"measurement\",\n",
    "                \"composite_score\",\n",
    "                \"norm_position_effect\",\n",
    "                \"norm_plate_effect\",\n",
    "                \"norm_week_effect\",\n",
    "            ]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Save final results\n",
    "    ranked_measurements.to_csv(checkpoint_files[\"ranked_measurements\"], index=False)\n",
    "\n",
    "    return {\n",
    "        \"position_effects\": position_effects,\n",
    "        \"plate_effects\": plate_effects,\n",
    "        \"week_effects\": week_effects,\n",
    "        \"ranked_measurements\": ranked_measurements,\n",
    "        \"correction_models\": correction_models,\n",
    "        \"pca\": pca,\n",
    "        \"pca_df\": pca_df,\n",
    "    }\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# df = pd.read_csv('your_data.csv')  # Load your data\n",
    "# results = main_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a99233aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def visualize_position_effects(position_effects):\n",
    "    \"\"\"Visualize position effects with a bar plot.\"\"\"\n",
    "    top_n = position_effects.nlargest(20, \"combined_effect\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=\"combined_effect\", y=\"measurement\", data=top_n, palette=\"viridis\")\n",
    "    plt.title(\"Top 20 Measurements by Combined Effect Size\")\n",
    "    plt.xlabel(\"Combined Effect Size\")\n",
    "    plt.ylabel(\"Measurement\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_plate_effects(plate_effects):\n",
    "    \"\"\"Visualize plate effects with a box plot.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=\"week\", y=\"p_value\", data=plate_effects)\n",
    "    plt.title(\"Plate Effects by Week\")\n",
    "    plt.xlabel(\"Week\")\n",
    "    plt.ylabel(\"P-value\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_week_effects(week_effects):\n",
    "    \"\"\"Visualize week effects with a box plot.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x=\"measurement\", y=\"p_value\", data=week_effects)\n",
    "    plt.title(\"Week Effects by Measurement\")\n",
    "    plt.xlabel(\"Measurement\")\n",
    "    plt.ylabel(\"P-value\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_ranked_measurements(ranked_measurements):\n",
    "    \"\"\"Visualize ranked measurements with a heatmap of composite scores.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    heatmap_data = ranked_measurements.pivot(\n",
    "        \"measurement\", \"norm_position_effect\", \"composite_score\"\n",
    "    )\n",
    "    sns.heatmap(\n",
    "        heatmap_data,\n",
    "        cmap=\"viridis\",\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cbar_kws={\"label\": \"Composite Score\"},\n",
    "    )\n",
    "    plt.title(\"Heatmap of Composite Scores for Ranked Measurements\")\n",
    "    plt.xlabel(\"Normalized Position Effect\")\n",
    "    plt.ylabel(\"Measurement\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_pca_results(pca_df):\n",
    "    \"\"\"Visualize PCA results with a scatter plot.\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(\n",
    "        x=\"PC1\", y=\"PC2\", hue=\"Week\", data=pca_df, palette=\"viridis\", alpha=0.7\n",
    "    )\n",
    "    plt.title(\"PCA Results\")\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.legend(title=\"Week\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# # Visualize each part\n",
    "# visualize_position_effects(results[\"position_effects\"])\n",
    "# visualize_plate_effects(results[\"plate_effects\"])\n",
    "# visualize_week_effects(results[\"week_effects\"].sort_values(\"p_value\").head(20))\n",
    "# visualize_ranked_measurements(results[\"ranked_measurements\"])\n",
    "# visualize_pca_results(results[\"pca_df\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7094cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = [\n",
    "    \"Metadata_Plate\",\n",
    "    \"Metadata_Treatment\",\n",
    "    \"Metadata_Concentration\",\n",
    "    'Metadata_Well_row',\n",
    "    'Metadata_Well_col',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a2e22a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metadata_Plate</th>\n",
       "      <th>Metadata_Treatment</th>\n",
       "      <th>Metadata_Concentration</th>\n",
       "      <th>Metadata_Well_row</th>\n",
       "      <th>Metadata_Well_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rtgill_QC_Cmpd2_plate3_w3_noncon</td>\n",
       "      <td>Rotenone</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rtgill_QC_Cmpd2_plate3_w3_noncon</td>\n",
       "      <td>Rotenone</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rtgill_QC_Cmpd2_plate3_w3_noncon</td>\n",
       "      <td>Rotenone</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rtgill_QC_Cmpd2_plate3_w3_noncon</td>\n",
       "      <td>Rotenone</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rtgill_QC_Cmpd2_plate3_w3_noncon</td>\n",
       "      <td>Rotenone</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metadata_Plate Metadata_Treatment  \\\n",
       "0  Rtgill_QC_Cmpd2_plate3_w3_noncon           Rotenone   \n",
       "1  Rtgill_QC_Cmpd2_plate3_w3_noncon           Rotenone   \n",
       "2  Rtgill_QC_Cmpd2_plate3_w3_noncon           Rotenone   \n",
       "3  Rtgill_QC_Cmpd2_plate3_w3_noncon           Rotenone   \n",
       "4  Rtgill_QC_Cmpd2_plate3_w3_noncon           Rotenone   \n",
       "\n",
       "   Metadata_Concentration  Metadata_Well_row  Metadata_Well_col  \n",
       "0                   0.200                  0                  0  \n",
       "1                   0.089                  0                  1  \n",
       "2                   0.040                  0                  2  \n",
       "3                   0.018                  0                  3  \n",
       "4                   0.008                  0                  4  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[relevant].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1c778cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Assuming your dataframe is called 'df'\n",
    "def create_dose_response_curves(df, response_col, cols2keep):\n",
    "    # Group by plate, treatment, and row\n",
    "    grouped = df.groupby(['Metadata_Plate', 'Metadata_Treatment', 'Metadata_Well_row'])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Iterate through each group\n",
    "    for (plate, treatment, row), group_data in grouped:\n",
    "        # Sort by column to ensure adjacent columns are processed in order\n",
    "        group_data = group_data.sort_values('Metadata_Well_col')\n",
    "        \n",
    "        # Check if columns are adjacent\n",
    "        columns = group_data['Metadata_Well_col'].values\n",
    "        if len(columns) > 1 and np.all(np.diff(columns) == 1):\n",
    "            # These are adjacent columns in the same row - we can create a dose response curve\n",
    "            \n",
    "            # Extract concentrations and response values\n",
    "            # Note: You'll need to add your response variable column name here\n",
    "            concentrations = group_data['Metadata_Concentration'].values\n",
    "            \n",
    "            add_cols = {col: group_data[col].values[0] for col in cols2keep}\n",
    "            \n",
    "            # For demonstration purposes, let's assume you have a column called 'Response'\n",
    "            # Replace 'Response' with your actual measurement column\n",
    "            response_values = group_data[response_col].values\n",
    "            \n",
    "            # Create a dose response curve\n",
    "            # This is where you would add your curve fitting code\n",
    "            dose_response_data = {\n",
    "                'Plate': plate,\n",
    "                'Treatment': treatment,\n",
    "                'Row': row,\n",
    "                'Columns': columns,\n",
    "                'Concentrations': concentrations,\n",
    "                'Response_Values': response_values,\n",
    "                \n",
    "                # Add other relevant data or curve parameters\n",
    "            }\n",
    "            dose_response_data.update(add_cols)\n",
    "\n",
    "            results.append(dose_response_data)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7ceeb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_dose_response_treatments(df, pc1, color_by_column, save_path=None, figsize=(14, 14)):\n",
    "    \"\"\"\n",
    "    Plot dose response data for all treatments in a 2x2 grid of subplots.\n",
    "    Shows individual lines without markers and adds median lines with error bars.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame containing the dose response data\n",
    "    pc1: Title component to display in the overall plot title\n",
    "    color_by_column: Column name to use for coloring the data points (e.g., 'Metadata_Week')\n",
    "    save_path: Path to save the plot (None to display only)\n",
    "    figsize: Size of the overall figure (width, height) in inches\n",
    "    \"\"\"\n",
    "    # Get unique treatments (should be 4)\n",
    "    unique_treatments = df['Treatment'].unique()\n",
    "    \n",
    "    # Create a 2x2 grid of subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize, sharex=False, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Get unique values for the color column\n",
    "    unique_color_values = df[color_by_column].unique()\n",
    "    color_palette = sns.color_palette(\"husl\", len(unique_color_values))\n",
    "    color_map = dict(zip(unique_color_values, color_palette))\n",
    "    \n",
    "    # Plot each treatment in its own subplot\n",
    "    for i, treatment in enumerate(unique_treatments):\n",
    "        if i >= 4:  # Just in case there are more than 4 treatments\n",
    "            print(f\"Warning: More than 4 treatments found. Only showing the first 4.\")\n",
    "            break\n",
    "            \n",
    "        ax = axes[i]\n",
    "        treatment_data = df[df['Treatment'] == treatment]\n",
    "\n",
    "        # Use defaultdict to automatically create lists for new concentration values\n",
    "        color_data = {color: defaultdict(list) for color in unique_color_values}\n",
    "        \n",
    "        # To store all unique concentrations for this treatment\n",
    "        all_concentrations = set()\n",
    "        \n",
    "        # Group by the color column\n",
    "        for color_value, group in treatment_data.groupby(color_by_column):\n",
    "            color = color_map[color_value]\n",
    "            \n",
    "            # Plot each set of data points in the group (lines only, no markers)\n",
    "            for idx, row in group.iterrows():\n",
    "                if 'Concentrations' in row:\n",
    "                    if treatment != \"DMSO\":\n",
    "                        concentrations = row['Concentrations']\n",
    "                    else:\n",
    "                        df[df['Treatment'] != \"DMSO\"].sample(1)['Concentrations']\n",
    "                    responses = row['Response_Values']\n",
    "                    \n",
    "                    # Convert to numpy arrays if they're lists\n",
    "                    if isinstance(concentrations, list):\n",
    "                        concentrations = np.array(concentrations)\n",
    "                    if isinstance(responses, list):\n",
    "                        responses = np.array(responses)\n",
    "                    \n",
    "                    # Plot the raw data as lines without markers\n",
    "                    ax.plot(concentrations, responses, '-', color=color, alpha=0.15, linewidth=0.8)\n",
    "                    \n",
    "                    # Store response values for each concentration to calculate median and error bars\n",
    "                    for conc, resp in zip(concentrations, responses):\n",
    "                        # Convert to float to handle any numeric type\n",
    "                        conc_float = float(conc)\n",
    "                        color_data[color_value][conc_float].append(resp)\n",
    "                        all_concentrations.add(conc_float)\n",
    "        \n",
    "        # Now add median lines with error bars for each color\n",
    "        for color_value in unique_color_values:\n",
    "            color = color_map[color_value]\n",
    "            \n",
    "            # Collect median and error bar data\n",
    "            x_values = []\n",
    "            medians = []\n",
    "            errors_lower = []\n",
    "            errors_upper = []\n",
    "            \n",
    "            for conc in sorted(color_data[color_value].keys()):\n",
    "                values = color_data[color_value][conc]\n",
    "                if values:  # Only if we have data for this concentration\n",
    "                    x_values.append(conc)\n",
    "                    median = np.median(values)\n",
    "                    medians.append(median)\n",
    "                    \n",
    "                    # Calculate 25th and 75th percentiles for error bars\n",
    "                    q1 = np.percentile(values, 25)\n",
    "                    q3 = np.percentile(values, 75)\n",
    "                    errors_lower.append(median - q1)\n",
    "                    errors_upper.append(q3 - median)\n",
    "            \n",
    "            if x_values:  # Only if we have data points\n",
    "                # Plot median line with error bars\n",
    "                ax.errorbar(\n",
    "                    x_values, medians, \n",
    "                    yerr=[errors_lower, errors_upper], \n",
    "                    fmt='o-', color=color, linewidth=2, markersize=6,\n",
    "                    capsize=4, capthick=1.5, elinewidth=1.5,\n",
    "                    label=f\"{color_by_column}={color_value}\"\n",
    "                )\n",
    "        \n",
    "        # Set subplot title and axes\n",
    "        ax.set_title(f\"{treatment}\", fontsize=14)\n",
    "        ax.set_xscale('log')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Set x-ticks to show all concentration values\n",
    "        unique_concentrations = sorted(all_concentrations)\n",
    "        ax.set_xticks(unique_concentrations)\n",
    "        ax.set_xticklabels([str(round(c, 2)) for c in unique_concentrations], rotation=45)\n",
    "        \n",
    "        # Add x and y labels to appropriate subplots\n",
    "        if i >= 2:  # Bottom row\n",
    "            ax.set_xlabel(\"Concentration\", fontsize=12)\n",
    "        if i % 2 == 0:  # Left column\n",
    "            ax.set_ylabel(\"Response\", fontsize=12)\n",
    "    \n",
    "    # Add a common legend at the bottom of the figure\n",
    "    handles, labels = [], []\n",
    "    for ax in axes:\n",
    "        h, l = ax.get_legend_handles_labels()\n",
    "        handles.extend(h)\n",
    "        labels.extend(l)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    fig.legend(by_label.values(), by_label.keys(), \n",
    "              title=color_by_column, loc='lower center', \n",
    "              bbox_to_anchor=(0.5, 0.02), ncol=min(5, len(by_label)))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    \n",
    "    # Add an overall title\n",
    "    fig.suptitle(f\"Dose Response of {pc1} by {color_by_column}\", fontsize=12, y=0.99)\n",
    "\n",
    "    # Save or show the plot\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c1b93fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch effects: 100%|██████████| 6/6 [00:22<00:00,  3.72s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:22<00:00,  3.81s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:23<00:00,  3.86s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:22<00:00,  3.72s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:22<00:00,  3.70s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:22<00:00,  3.78s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:21<00:00,  3.55s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:23<00:00,  3.97s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:21<00:00,  3.51s/it]\n",
      "Processing batch effects: 100%|██████████| 6/6 [00:23<00:00,  3.98s/it]\n",
      "                                            \r"
     ]
    }
   ],
   "source": [
    "for pc1 in tqdm(mahanolobis_cols, desc = \"Processing channels\", total = len(only_pc1), leave = False):\n",
    "    result_df = create_dose_response_curves(df, pc1, metadata_plate_effects)\n",
    "    # for treatment in df[\"Metadata_Treatment\"].unique():\n",
    "    for batch_effect in tqdm(metadata_plate_effects, desc=\"Processing batch effects\", leave = True):\n",
    "        plot_dose_response_treatments(\n",
    "            result_df,\n",
    "            pc1,\n",
    "            color_by_column=batch_effect,\n",
    "            save_path = f\"figures/dose_response_mahanolobis_{pc1}_by_{batch_effect}.png\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f13360d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pc1 in tqdm(only_pc1, desc = \"Processing channels\", total = len(only_pc1), leave = False):\n",
    "#     result_df = create_dose_response_curves(df, pc1, metadata_plate_effects)\n",
    "#     # for treatment in df[\"Metadata_Treatment\"].unique():\n",
    "#     for batch_effect in tqdm(metadata_plate_effects, desc=\"Processing batch effects\", leave = True):\n",
    "#         plot_dose_response_treatments(\n",
    "#             result_df,\n",
    "#             pc1,\n",
    "#             color_by_column=batch_effect,\n",
    "#             save_path = f\"figures/dose_response_{pc1}_by_{batch_effect}.png\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2adf73",
   "metadata": {},
   "source": [
    "# See if dose response curves change over the plate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a0078",
   "metadata": {},
   "source": [
    "Rank concentrations, plot by concentration see if DMSO seperates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
